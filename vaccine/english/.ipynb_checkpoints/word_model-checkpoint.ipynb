{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import codecs\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "newspapers = pd.read_csv('C:/Users/jw156/Ironhack/vaccine/newspapers.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hrefs', 'title', 'new_title', 'id', 'date', 'newspaper_name',\n",
       "       'vaccine'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newspapers.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "newspapers = newspapers.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS Determination of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "newspapers = newspapers.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize(\"running\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_headline(headline):\n",
    "    new_headline = headline.split(' ')\n",
    "    word_list = []\n",
    "    for word in new_headline:\n",
    "        text = word_tokenize(word)\n",
    "        postition_tag = nltk.pos_tag(text)\n",
    "        word_list.append(postition_tag)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def is_proper_noun(tag):\n",
    "    return tag in ['NNP', 'NNPS']\n",
    "\n",
    "def is_noun(tag):\n",
    "    return tag in ['NN', 'NNS']\n",
    "\n",
    "\n",
    "def is_verb(tag):\n",
    "    return tag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "\n",
    "\n",
    "def is_adverb(tag):\n",
    "    return tag in ['RB', 'RBR', 'RBS']\n",
    "\n",
    "\n",
    "def is_adjective(tag):\n",
    "    return tag in ['JJ', 'JJR', 'JJS']\n",
    "\n",
    "\n",
    "\n",
    "def penn_to_wn(headline_list):\n",
    "    tagged_list = []\n",
    "    for tag in headline_list:\n",
    "        tag = list(tag[0])\n",
    "        if is_adjective(tag[1]):\n",
    "            tag[1] = (wn.ADJ)\n",
    "            tagged_list.append(tag)\n",
    "        elif is_noun(tag[1]):\n",
    "            tag[1] =(wn.NOUN)\n",
    "            tagged_list.append(tag)\n",
    "        elif is_adverb(tag[1]):\n",
    "            tag[1] =(wn.ADV)\n",
    "            tagged_list.append(tag)\n",
    "        elif is_verb(tag[1]):\n",
    "            tag[1] =(wn.VERB)\n",
    "            tagged_list.append(tag)\n",
    "        elif is_proper_noun(tag[1]):\n",
    "            tag[1] =('NNP')\n",
    "            tagged_list.append(tag)\n",
    "        else:\n",
    "            continue\n",
    "    return tagged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "newspapers['pos_headline'] = newspapers['title'].apply(pos_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Boris', 'NNP']\n",
      "['Johnson', 'NNP']\n",
      "['receives', 'NNS']\n",
      "['Oxford/AstraZeneca', 'NN']\n",
      "['Covid', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['Scepticism', 'NN']\n",
      "['over', 'IN']\n",
      "['Oxford', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['threatens', 'NNS']\n",
      "['Europe', 'NNP']\n",
      "['immunisation', 'NN']\n",
      "['push', 'NN']\n",
      "['Thursday', 'NNP']\n",
      "['briefing', 'NN']\n",
      "['EU', 'NNP']\n",
      "['experts', 'NNS']\n",
      "['to', 'TO']\n",
      "['give', 'VB']\n",
      "['Oxford', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['verdict', 'NN']\n",
      "['Oxford/AstraZeneca', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['which', 'WDT']\n",
      "['countries', 'NNS']\n",
      "['have', 'VB']\n",
      "['paused', 'VBN']\n",
      "['jab', 'NN']\n",
      "['and', 'CC']\n",
      "['why', 'WRB']\n",
      "['Chaos', 'NN']\n",
      "['in', 'IN']\n",
      "['Germany', 'NNP']\n",
      "['and', 'CC']\n",
      "['Italy', 'NNP']\n",
      "['after', 'IN']\n",
      "['suspension', 'NN']\n",
      "['of', 'IN']\n",
      "['Oxford', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['Europe', 'NNP']\n",
      "['caution', 'NN']\n",
      "['over', 'IN']\n",
      "['Oxford', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['about', 'IN']\n",
      "['more', 'RBR']\n",
      "['than', 'IN']\n",
      "['the', 'DT']\n",
      "['science', 'NN']\n",
      "['Covid', 'NN']\n",
      "['Germany', 'NNP']\n",
      "['and', 'CC']\n",
      "['France', 'NNP']\n",
      "['under', 'IN']\n",
      "['pressure', 'NN']\n",
      "['to', 'TO']\n",
      "['shift', 'NN']\n",
      "['Oxford', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['Oxford/AstraZeneca', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['rollout', 'NN']\n",
      "['plan', 'NN']\n",
      "['changed', 'VBN']\n",
      "['following', 'VBG']\n",
      "['approval', 'NN']\n",
      "['Belgium', 'NN']\n",
      "['considers', 'NNS']\n",
      "['U-turn', 'NN']\n",
      "['on', 'IN']\n",
      "['Oxford', 'NN']\n",
      "['Covid', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['for', 'IN']\n",
      "['over-55s', 'NN']\n",
      "['Belgium', 'NN']\n",
      "['slow', 'VB']\n",
      "['to', 'TO']\n",
      "['distribute', 'NN']\n",
      "['Oxford', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['doses', 'NNS']\n",
      "['as', 'IN']\n",
      "['Covid', 'NN']\n",
      "['cases', 'NNS']\n",
      "['rise', 'NN']\n",
      "['Debenhams', 'NNS']\n",
      "['to', 'TO']\n",
      "['shut', 'NN']\n",
      "['six', 'CD']\n",
      "['stores', 'NNS']\n",
      "['including', 'VBG']\n",
      "['Oxford', 'NN']\n",
      "['Street', 'NNP']\n",
      "['flagship', 'NN']\n",
      "['Oxford', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['spat', 'NN']\n",
      "['could', 'MD']\n",
      "['lead', 'NN']\n",
      "['to', 'TO']\n",
      "['divergence', 'NN']\n",
      "['in', 'IN']\n",
      "['Covid', 'NN']\n",
      "['strategies', 'NNS']\n",
      "['What', 'WP']\n",
      "['difference', 'NN']\n",
      "['will', 'MD']\n",
      "['Oxford/AstraZeneca', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['make', 'VB']\n",
      "['in', 'IN']\n",
      "['UK', 'NNP']\n",
      "['Oxford/AstraZeneca', 'NN']\n",
      "['Covid', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['given', 'VBN']\n",
      "['full', 'JJ']\n",
      "['approval', 'NN']\n",
      "['by', 'IN']\n",
      "['EU', 'NN']\n",
      "['regulator', 'NN']\n",
      "['M', 'NNP']\n",
      "['to', 'TO']\n",
      "['redevelop', 'NN']\n",
      "['big', 'JJ']\n",
      "['Oxford', 'NN']\n",
      "['Street', 'NNP']\n",
      "['store', 'NN']\n",
      "['as', 'IN']\n",
      "['shoppers', 'NNS']\n",
      "['move', 'NN']\n",
      "['online', 'NN']\n",
      "['M', 'NNP']\n",
      "['to', 'TO']\n",
      "['redevelop', 'NN']\n",
      "['big', 'JJ']\n",
      "['Oxford', 'NN']\n",
      "['Street', 'NNP']\n",
      "['store', 'NN']\n",
      "['as', 'IN']\n",
      "['shoppers', 'NNS']\n",
      "['move', 'NN']\n",
      "['online', 'NN']\n",
      "['Questions', 'NNS']\n",
      "['hang', 'NN']\n",
      "['over', 'IN']\n",
      "['UK', 'NNP']\n",
      "['rollout', 'NN']\n",
      "['of', 'IN']\n",
      "['Oxford/AstraZeneca', 'NN']\n",
      "['jab', 'NN']\n",
      "['Oxford/AstraZeneca', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['to', 'TO']\n",
      "['undergo', 'NN']\n",
      "['new', 'JJ']\n",
      "['global', 'JJ']\n",
      "['trial', 'NN']\n",
      "['Life', 'NN']\n",
      "['savers', 'NNS']\n",
      "['the', 'DT']\n",
      "['amazing', 'VBG']\n",
      "['story', 'NN']\n",
      "['of', 'IN']\n",
      "['the', 'DT']\n",
      "['Oxford/AstraZeneca', 'NN']\n",
      "['Covid', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['Oxford', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['still', 'RB']\n",
      "['under', 'IN']\n",
      "['review', 'NN']\n",
      "['says', 'VBZ']\n",
      "['UK', 'NN']\n",
      "['medicine', 'NN']\n",
      "['agency', 'NN']\n",
      "['Hancock', 'NN']\n",
      "['seizes', 'NNS']\n",
      "['on', 'IN']\n",
      "['new', 'JJ']\n",
      "['data', 'NNS']\n",
      "['to', 'TO']\n",
      "['counter', 'NN']\n",
      "['EU', 'NN']\n",
      "['doubts', 'NNS']\n",
      "['on', 'IN']\n",
      "['Oxford', 'NN']\n",
      "['jab', 'NN']\n",
      "['Tuesday', 'NNP']\n",
      "['briefing', 'NN']\n",
      "['Vaccine', 'NN']\n",
      "['success', 'NN']\n",
      "['boosts', 'NNS']\n",
      "['Oxford', 'NN']\n",
      "['jab', 'NN']\n",
      "['hopes', 'NNS']\n",
      "['Markets', 'NNS']\n",
      "['boosted', 'VBN']\n",
      "['as', 'IN']\n",
      "['Oxford', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['rollout', 'NN']\n",
      "['begins', 'NNS']\n",
      "['–', 'NN']\n",
      "['business', 'NN']\n",
      "['live', 'JJ']\n",
      "['UK', 'NN']\n",
      "['hospitals', 'NNS']\n",
      "['receive', 'NN']\n",
      "['Oxford/AstraZeneca', 'NN']\n",
      "['Covid', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['for', 'IN']\n",
      "['Monday', 'NNP']\n",
      "['rollout', 'NN']\n",
      "['UK', 'NN']\n",
      "['hospitals', 'NNS']\n",
      "['receive', 'NN']\n",
      "['Oxford/AstraZeneca', 'NN']\n",
      "['Covid', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['for', 'IN']\n",
      "['Monday', 'NNP']\n",
      "['rollout', 'NN']\n",
      "['Oxford', 'NN']\n",
      "['Covid', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['has', 'VBZ']\n",
      "['10', 'CD']\n",
      "['efficacy', 'NN']\n",
      "['against', 'IN']\n",
      "['South', 'NNP']\n",
      "['African', 'JJ']\n",
      "['variant', 'NN']\n",
      "['study', 'NN']\n",
      "['suggests', 'NNS']\n",
      "['Why', 'WRB']\n",
      "['has', 'VBZ']\n",
      "['Germany', 'NNP']\n",
      "['advised', 'VBN']\n",
      "['against', 'IN']\n",
      "['Oxford/AstraZeneca', 'NN']\n",
      "['jab', 'NN']\n",
      "['for', 'IN']\n",
      "['over-65s', 'NN']\n",
      "['Study', 'NN']\n",
      "['shows', 'NNS']\n",
      "['Oxford', 'NN']\n",
      "['Covid', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['has', 'VBZ']\n",
      "['less', 'RBR']\n",
      "['protection', 'NN']\n",
      "['against', 'IN']\n",
      "['South', 'NNP']\n",
      "['African', 'JJ']\n",
      "['variant', 'NN']\n",
      "['How', 'WRB']\n",
      "['is', 'VBZ']\n",
      "['the', 'DT']\n",
      "['Oxford', 'NN']\n",
      "['Covid', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['being', 'VBG']\n",
      "['deployed', 'NN']\n",
      "['in', 'IN']\n",
      "['England', 'NNP']\n",
      "['Just', 'RB']\n",
      "['how', 'WRB']\n",
      "['effective', 'JJ']\n",
      "['is', 'VBZ']\n",
      "['the', 'DT']\n",
      "['Oxford', 'NN']\n",
      "['coronavirus', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['for', 'IN']\n",
      "['the', 'DT']\n",
      "['over-65s', 'NN']\n",
      "['|', 'NN']\n",
      "['David', 'NNP']\n",
      "['Spiegelhalter', 'NN']\n",
      "['and', 'CC']\n",
      "['Anthony', 'NN']\n",
      "['Masters', 'NNS']\n",
      "[\"'Happy\", 'JJ']\n",
      "['vaccine', 'NN']\n",
      "['day', 'NN']\n",
      "['at', 'IN']\n",
      "['Welsh', 'NN']\n",
      "['factory', 'NN']\n",
      "['proudly', 'RB']\n",
      "['preparing', 'VBG']\n",
      "['Oxford', 'NN']\n",
      "['doses', 'NNS']\n",
      "['A', 'DT']\n",
      "['series', 'NN']\n",
      "['of', 'IN']\n",
      "['knocks', 'NNS']\n",
      "['Oxford/AstraZeneca', 'NNP']\n",
      "['bumpy', 'NN']\n",
      "['road', 'NN']\n",
      "['to', 'TO']\n",
      "['Covid', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['confidence', 'NN']\n",
      "['Oxford', 'NN']\n",
      "['AstraZeneca', 'NN']\n",
      "['Covid', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['everything', 'NN']\n",
      "['we', 'PRP']\n",
      "['know', 'VB']\n",
      "['so', 'RB']\n",
      "['far', 'RB']\n",
      "['A', 'DT']\n",
      "['series', 'NN']\n",
      "['of', 'IN']\n",
      "['knocks', 'NNS']\n",
      "['Oxford/AstraZeneca', 'NNP']\n",
      "['bumpy', 'NN']\n",
      "['road', 'NN']\n",
      "['to', 'TO']\n",
      "['Covid', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['confidence', 'NN']\n",
      "['Spain', 'NNP']\n",
      "['joins', 'NNS']\n",
      "['France', 'NNP']\n",
      "['Germany', 'NNP']\n",
      "['and', 'CC']\n",
      "['Italy', 'NNP']\n",
      "['in', 'IN']\n",
      "['pausing', 'VBG']\n",
      "['Oxford/AstraZeneca', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['–', 'NN']\n",
      "['as', 'IN']\n",
      "['it', 'PRP']\n",
      "['happened', 'VBD']\n",
      "['High', 'JJ']\n",
      "['street', 'NN']\n",
      "['pharmacies', 'NNS']\n",
      "['to', 'TO']\n",
      "['start', 'NN']\n",
      "['offering', 'NN']\n",
      "['Oxford', 'NN']\n",
      "['Covid', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['next', 'JJ']\n",
      "['week', 'NN']\n",
      "['UK', 'NN']\n",
      "['defends', 'NNS']\n",
      "['Oxford', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['as', 'IN']\n",
      "['Germany', 'NNP']\n",
      "['advises', 'NNS']\n",
      "['against', 'IN']\n",
      "['use', 'NN']\n",
      "['on', 'IN']\n",
      "['over-65s', 'NN']\n",
      "['Covid', 'NN']\n",
      "['Oxford', 'NN']\n",
      "['trial', 'NN']\n",
      "['to', 'TO']\n",
      "['test', 'NN']\n",
      "['efficacy', 'NN']\n",
      "['of', 'IN']\n",
      "['mix', 'NN']\n",
      "['of', 'IN']\n",
      "['vaccines', 'NNS']\n",
      "['for', 'IN']\n",
      "['individuals', 'NNS']\n",
      "['There', 'EX']\n",
      "['no', 'DT']\n",
      "['proof', 'NN']\n",
      "['the', 'DT']\n",
      "['Oxford', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['causes', 'NNS']\n",
      "['blood', 'NN']\n",
      "['clots', 'NNS']\n",
      "['So', 'RB']\n",
      "['why', 'WRB']\n",
      "['are', 'VBP']\n",
      "['people', 'NNS']\n",
      "['worried', 'VBN']\n",
      "['|', 'NN']\n",
      "['David', 'NNP']\n",
      "['Spiegelhalter', 'NN']\n",
      "['No', 'DT']\n",
      "['10', 'CD']\n",
      "['wanted', 'VBD']\n",
      "['union', 'NN']\n",
      "['flag', 'NN']\n",
      "['on', 'IN']\n",
      "['Oxford', 'NN']\n",
      "['coronavirus', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['kits', 'NNS']\n",
      "['Oxford', 'NN']\n",
      "['animal-only', 'RB']\n",
      "['antibiotic', 'JJ']\n",
      "['lab', 'NN']\n",
      "['could', 'MD']\n",
      "['prop', 'NN']\n",
      "['up', 'RB']\n",
      "['intensive', 'JJ']\n",
      "['farming', 'NN']\n",
      "['critics', 'NNS']\n",
      "['say', 'VB']\n",
      "['WHO', 'WP']\n",
      "['backs', 'NNS']\n",
      "['use', 'NN']\n",
      "['of', 'IN']\n",
      "['Oxford/AstraZeneca', 'NN']\n",
      "['Covid', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['for', 'IN']\n",
      "['adults', 'NNS']\n",
      "['of', 'IN']\n",
      "['all', 'DT']\n",
      "['ages', 'NNS']\n",
      "['NHS', 'NN']\n",
      "['could', 'MD']\n",
      "['vaccinate', 'NN']\n",
      "['UK', 'NN']\n",
      "['against', 'IN']\n",
      "['Covid', 'NN']\n",
      "['in', 'IN']\n",
      "['five', 'CD']\n",
      "['days', 'NNS']\n",
      "['says', 'VBZ']\n",
      "['Oxford', 'NN']\n",
      "['professor', 'NN']\n",
      "['Oxford', 'NN']\n",
      "['University', 'NNP']\n",
      "['resumes', 'NNS']\n",
      "['Covid-19', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['trials', 'NNS']\n",
      "['Only', 'RB']\n",
      "[\"'small\", 'NN']\n",
      "['chance', 'NN']\n",
      "['Oxford', 'NN']\n",
      "['Covid', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['ready', 'JJ']\n",
      "['by', 'IN']\n",
      "['Christmas', 'NN']\n",
      "['UK', 'NN']\n",
      "['to', 'TO']\n",
      "['begin', 'NN']\n",
      "['using', 'VBG']\n",
      "['Oxford', 'NN']\n",
      "['Covid', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['as', 'IN']\n",
      "['PM', 'NN']\n",
      "['strikes', 'NNS']\n",
      "['hopeful', 'NN']\n",
      "['tone', 'NN']\n",
      "['Oxford', 'NN']\n",
      "['Covid', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['to', 'TO']\n",
      "['be', 'VB']\n",
      "['combined', 'VBN']\n",
      "['with', 'IN']\n",
      "['Sputnik', 'NN']\n",
      "['jab', 'NN']\n",
      "['for', 'IN']\n",
      "['trial', 'NN']\n",
      "['Oxford/AstraZeneca', 'NN']\n",
      "['Covid', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['has', 'VBZ']\n",
      "['70', 'CD']\n",
      "['efficacy', 'NN']\n",
      "['full', 'JJ']\n",
      "['trial', 'NN']\n",
      "['data', 'NNS']\n",
      "['shows', 'NNS']\n",
      "['How', 'WRB']\n",
      "['and', 'CC']\n",
      "['when', 'WRB']\n",
      "['will', 'MD']\n",
      "['Oxford/AstraZeneca', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['be', 'VB']\n",
      "['rolled', 'VBN']\n",
      "['out', 'IN']\n",
      "['in', 'IN']\n",
      "['UK', 'NNP']\n",
      "['How', 'WRB']\n",
      "['well', 'RB']\n",
      "['does', 'VBZ']\n",
      "['the', 'DT']\n",
      "['Oxford', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['work', 'NN']\n",
      "['What', 'WP']\n",
      "['we', 'PRP']\n",
      "['know', 'VB']\n",
      "['so', 'RB']\n",
      "['far', 'RB']\n",
      "['Moderna', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['trial', 'NN']\n",
      "['results', 'NNS']\n",
      "['bode', 'NN']\n",
      "['well', 'RB']\n",
      "['for', 'IN']\n",
      "['Oxford/AstraZeneca', 'NN']\n",
      "['jab', 'NN']\n",
      "[\"'It\", 'NN']\n",
      "['a', 'DT']\n",
      "['great', 'JJ']\n",
      "['day', 'NN']\n",
      "['Oxford', 'NN']\n",
      "['coronavirus', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['volunteers', 'NNS']\n",
      "['on', 'IN']\n",
      "['trial', 'NN']\n",
      "['data', 'NNS']\n",
      "['Hancock', 'NN']\n",
      "['hails', 'NNS']\n",
      "['Oxford', 'NN']\n",
      "['Covid', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['at', 'IN']\n",
      "['surgery', 'NN']\n",
      "['that', 'IN']\n",
      "['had', 'VBD']\n",
      "['yet', 'RB']\n",
      "['to', 'TO']\n",
      "['receive', 'NN']\n",
      "['doses', 'NNS']\n",
      "['Oxford', 'NN']\n",
      "['Covid', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['hit', 'NN']\n",
      "['90', 'CD']\n",
      "['success', 'NN']\n",
      "['rate', 'NN']\n",
      "['thanks', 'NNS']\n",
      "['to', 'TO']\n",
      "['dosing', 'VBG']\n",
      "['error', 'NN']\n",
      "['Are', 'NN']\n",
      "['you', 'PRP']\n",
      "['getting', 'VBG']\n",
      "['the', 'DT']\n",
      "['Oxford/AstraZeneca', 'NN']\n",
      "['coronavirus', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['this', 'DT']\n",
      "['week', 'NN']\n",
      "['in', 'IN']\n",
      "['the', 'DT']\n",
      "['UK', 'NNP']\n",
      "['India', 'NNP']\n",
      "['approves', 'NNS']\n",
      "['Oxford/AstraZeneca', 'NN']\n",
      "['vaccine', 'NN']\n",
      "['Italy', 'NNP']\n",
      "['delays', 'NNS']\n",
      "['opening', 'NN']\n",
      "['ski', 'NN']\n",
      "['resorts', 'NNS']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-de2a16d2f7a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnewspapers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reduced_pos_headline'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnewspapers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pos_headline'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpenn_to_wn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4198\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4200\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-4f5f21092aa9>\u001b[0m in \u001b[0;36mpenn_to_wn\u001b[1;34m(headline_list)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mtagged_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mheadline_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mtag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_adjective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "newspapers['reduced_pos_headline'] = newspapers['pos_headline'].apply(penn_to_wn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hrefs</th>\n",
       "      <th>title</th>\n",
       "      <th>new_title</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>newspaper_name</th>\n",
       "      <th>vaccine</th>\n",
       "      <th>pos_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.theguardian.com/politics/2021/mar/...</td>\n",
       "      <td>Boris Johnson receives Oxford/AstraZeneca Covi...</td>\n",
       "      <td>bor johnson receiv oxfordastrazenec covid vaccin</td>\n",
       "      <td>politics</td>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>guardian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[(Boris, NNP)], [(Johnson, NNP)], [(receives,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.theguardian.com/world/2021/feb/19/...</td>\n",
       "      <td>Scepticism over Oxford vaccine threatens Europ...</td>\n",
       "      <td>sceiv oxford vaccin threatens europ immun push</td>\n",
       "      <td>world</td>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>guardian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[(Scepticism, NN)], [(over, IN)], [(Oxford, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.theguardian.com/world/2021/mar/18/...</td>\n",
       "      <td>Thursday briefing: EU's experts to give Oxford...</td>\n",
       "      <td>thursday brief eu expert giv oxford vaccin ver...</td>\n",
       "      <td>world</td>\n",
       "      <td>2021-03-18</td>\n",
       "      <td>guardian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[(Thursday, NNP)], [(briefing, NN), (:, :)], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.theguardian.com/world/2021/mar/16/...</td>\n",
       "      <td>Oxford/AstraZeneca vaccine: which countries ha...</td>\n",
       "      <td>oxfordastrazenec vaccin country paus jab</td>\n",
       "      <td>world</td>\n",
       "      <td>2021-03-16</td>\n",
       "      <td>guardian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[(Oxford/AstraZeneca, NN)], [(vaccine, NN), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.theguardian.com/world/2021/mar/16/...</td>\n",
       "      <td>Chaos in Germany and Italy after suspension of...</td>\n",
       "      <td>chao germany ita suspend oxford vaccin</td>\n",
       "      <td>world</td>\n",
       "      <td>2021-03-16</td>\n",
       "      <td>guardian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[(Chaos, NN)], [(in, IN)], [(Germany, NNP)], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62019</th>\n",
       "      <td>https://www.independent.co.uk/news/uk/politics...</td>\n",
       "      <td>Extreme lockdown laws extended for a further s...</td>\n",
       "      <td>extrem lockdown law extend six month despit ma...</td>\n",
       "      <td>coronavirus</td>\n",
       "      <td>2021-03-25</td>\n",
       "      <td>independent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[(Extreme, NN)], [(lockdown, NN)], [(laws, NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62020</th>\n",
       "      <td>https://www.independent.co.uk/news/uk/politics...</td>\n",
       "      <td>Extreme lockdown laws extended for a further s...</td>\n",
       "      <td>extrem lockdown law extend six month despit ma...</td>\n",
       "      <td>coronavirus</td>\n",
       "      <td>2021-03-25</td>\n",
       "      <td>independent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[(Extreme, NN)], [(lockdown, NN)], [(laws, NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62021</th>\n",
       "      <td>https://www.independent.co.uk/independentpremi...</td>\n",
       "      <td>The problem with Johnson’s vaccine passports f...</td>\n",
       "      <td>the problem johnson vaccin passport pub</td>\n",
       "      <td>business</td>\n",
       "      <td>2021-03-25</td>\n",
       "      <td>independent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[(The, DT)], [(problem, NN)], [(with, IN)], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62022</th>\n",
       "      <td>https://www.independent.co.uk/voices/editorial...</td>\n",
       "      <td>Reality is dawning on the EU: export bans are ...</td>\n",
       "      <td>real dawn eu export ban counterproduc cas covi...</td>\n",
       "      <td>uk</td>\n",
       "      <td>2021-03-25</td>\n",
       "      <td>independent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[(Reality, NN)], [(is, VBZ)], [(dawning, VBG)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62023</th>\n",
       "      <td>https://www.independent.co.uk/news/uk/home-new...</td>\n",
       "      <td>University of Aberdeen to become one of the fi...</td>\n",
       "      <td>univers aberdeen becom on first uk institut re...</td>\n",
       "      <td>uk</td>\n",
       "      <td>2021-03-25</td>\n",
       "      <td>independent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[(University, NNP)], [(of, IN)], [(Aberdeen, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62024 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   hrefs  \\\n",
       "0      https://www.theguardian.com/politics/2021/mar/...   \n",
       "1      https://www.theguardian.com/world/2021/feb/19/...   \n",
       "2      https://www.theguardian.com/world/2021/mar/18/...   \n",
       "3      https://www.theguardian.com/world/2021/mar/16/...   \n",
       "4      https://www.theguardian.com/world/2021/mar/16/...   \n",
       "...                                                  ...   \n",
       "62019  https://www.independent.co.uk/news/uk/politics...   \n",
       "62020  https://www.independent.co.uk/news/uk/politics...   \n",
       "62021  https://www.independent.co.uk/independentpremi...   \n",
       "62022  https://www.independent.co.uk/voices/editorial...   \n",
       "62023  https://www.independent.co.uk/news/uk/home-new...   \n",
       "\n",
       "                                                   title  \\\n",
       "0      Boris Johnson receives Oxford/AstraZeneca Covi...   \n",
       "1      Scepticism over Oxford vaccine threatens Europ...   \n",
       "2      Thursday briefing: EU's experts to give Oxford...   \n",
       "3      Oxford/AstraZeneca vaccine: which countries ha...   \n",
       "4      Chaos in Germany and Italy after suspension of...   \n",
       "...                                                  ...   \n",
       "62019  Extreme lockdown laws extended for a further s...   \n",
       "62020  Extreme lockdown laws extended for a further s...   \n",
       "62021  The problem with Johnson’s vaccine passports f...   \n",
       "62022  Reality is dawning on the EU: export bans are ...   \n",
       "62023  University of Aberdeen to become one of the fi...   \n",
       "\n",
       "                                               new_title           id  \\\n",
       "0      bor johnson receiv oxfordastrazenec covid vaccin      politics   \n",
       "1        sceiv oxford vaccin threatens europ immun push         world   \n",
       "2      thursday brief eu expert giv oxford vaccin ver...        world   \n",
       "3              oxfordastrazenec vaccin country paus jab         world   \n",
       "4                chao germany ita suspend oxford vaccin         world   \n",
       "...                                                  ...          ...   \n",
       "62019  extrem lockdown law extend six month despit ma...  coronavirus   \n",
       "62020  extrem lockdown law extend six month despit ma...  coronavirus   \n",
       "62021           the problem johnson vaccin passport pub      business   \n",
       "62022  real dawn eu export ban counterproduc cas covi...           uk   \n",
       "62023  univers aberdeen becom on first uk institut re...           uk   \n",
       "\n",
       "             date newspaper_name vaccine  \\\n",
       "0      2021-03-19       guardian     NaN   \n",
       "1      2021-02-19       guardian     NaN   \n",
       "2      2021-03-18       guardian     NaN   \n",
       "3      2021-03-16       guardian     NaN   \n",
       "4      2021-03-16       guardian     NaN   \n",
       "...           ...            ...     ...   \n",
       "62019  2021-03-25    independent     NaN   \n",
       "62020  2021-03-25    independent     NaN   \n",
       "62021  2021-03-25    independent     NaN   \n",
       "62022  2021-03-25    independent     NaN   \n",
       "62023  2021-03-25    independent     NaN   \n",
       "\n",
       "                                            pos_headline  \n",
       "0      [[(Boris, NNP)], [(Johnson, NNP)], [(receives,...  \n",
       "1      [[(Scepticism, NN)], [(over, IN)], [(Oxford, N...  \n",
       "2      [[(Thursday, NNP)], [(briefing, NN), (:, :)], ...  \n",
       "3      [[(Oxford/AstraZeneca, NN)], [(vaccine, NN), (...  \n",
       "4      [[(Chaos, NN)], [(in, IN)], [(Germany, NNP)], ...  \n",
       "...                                                  ...  \n",
       "62019  [[(Extreme, NN)], [(lockdown, NN)], [(laws, NN...  \n",
       "62020  [[(Extreme, NN)], [(lockdown, NN)], [(laws, NN...  \n",
       "62021  [[(The, DT)], [(problem, NN)], [(with, IN)], [...  \n",
       "62022  [[(Reality, NN)], [(is, VBZ)], [(dawning, VBG)...  \n",
       "62023  [[(University, NNP)], [(of, IN)], [(Aberdeen, ...  \n",
       "\n",
       "[62024 rows x 8 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newspapers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Sense Disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('lockdown.n.01')\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "\n",
    "x = 'The pandemic caused a lockdown'\n",
    "\n",
    "print(lesk(x.split(), 'lockdown', 'n'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
